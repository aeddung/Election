{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekdR6B8NJCRd",
        "outputId": "04b1933d-b1e0-43c4-93d1-82760a396c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/SOYO/Election/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5s-S5ZOEqsE",
        "outputId": "876ea1a8-0cc3-4e55-9b07-e5636916686a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-libmysqlclient-dev is already the newest version (1.0.4).\n",
            "default-libmysqlclient-dev set to manually installed.\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3-dev default-libmysqlclient-dev\n",
        "!pip install -q pymysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vPLK_qZyE62E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "import pymysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe2D4TrSI74s",
        "outputId": "2ece1dbc-8c6d-4b34-febe-e1476e765d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 448 kB 61.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTpCrtRfI9Nb",
        "outputId": "21e25856-de47-4876-81a4-dc85b7bf9bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "isZimn7kFCV3"
      },
      "outputs": [],
      "source": [
        "host = '****.*****.ap-northeast-2.rds.amazonaws.com'\n",
        "port = 3306\n",
        "username = '***'\n",
        "password = '****'\n",
        "db = '****'\n",
        "\n",
        "conn = pymysql.connect(host=host, port=port, user=username, password=password, db=db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dXgEoX9IGcO_"
      },
      "outputs": [],
      "source": [
        "# 유튜브 라이브 댓글\n",
        "sql_state = 'SELECT * FROM youtube_comment_live'\n",
        "\n",
        "youtube_df = pd.read_sql_query(sql_state, conn)\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiZEcy7QNpQ9",
        "outputId": "c10e7c6b-9353-4893-ce50-3f4e0795eb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(306667, 6)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "13    104675\n",
              "10     96913\n",
              "12     55659\n",
              "11     49420\n",
              "Name: youtube_id, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 새로 가져온 영상 source들\n",
        "print(youtube_df.shape)\n",
        "youtube_df['youtube_id'].value_counts() # 10: mbc(3차), 11: sbs(3차), 12: kbs(4차), 13: mbc(4차)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cCvdq3x9HtQC"
      },
      "outputs": [],
      "source": [
        "mbc_3rd = youtube_df.loc[youtube_df['youtube_id'] == 10]\n",
        "sbs_3rd = youtube_df.loc[youtube_df['youtube_id'] == 11]\n",
        "kbs_4th = youtube_df.loc[youtube_df['youtube_id'] == 12]\n",
        "mbc_4th = youtube_df.loc[youtube_df['youtube_id'] == 13]\n",
        "\n",
        "mbc_3rd.reset_index(drop=True, inplace=True)\n",
        "sbs_3rd.reset_index(drop=True, inplace=True)\n",
        "kbs_4th.reset_index(drop=True, inplace=True)\n",
        "mbc_4th.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KaIhhyl3I_Za"
      },
      "outputs": [],
      "source": [
        "# stopwords 목록 가져오기\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "kor_stopwords = []\n",
        "with open('/content/drive/My Drive/Colab Notebooks/SOYO/Election/dataset/korean_stopwords.txt', 'r') as f:\n",
        "  for line in f:\n",
        "    kor_stopwords.append(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ABtV9uVfPQrk"
      },
      "outputs": [],
      "source": [
        "def onlyhangul(x):\n",
        "  pattern = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글 및 띄어쓰기에 해당되지 않는 부분(영어, 기호, 이모티콘 등)\n",
        "  results = pattern.sub('', str(x))\n",
        "  # removed_string = pattern.findall(x)\n",
        "  return results\n",
        "\n",
        "def remove_stopwords(x):\n",
        "  result = []\n",
        "  word_tokens = word_tokenize(str(x))\n",
        "  for w in word_tokens:\n",
        "      if w not in kor_stopwords:\n",
        "          result.append(w)\n",
        "  \n",
        "  if len(result) == 0:\n",
        "    return 0\n",
        "  return ' '.join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_0qV4cRf_J"
      },
      "source": [
        "# 유튜브 라이브 댓글 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2s1d-qeHxnZ",
        "outputId": "be29cecb-31ae-4f07-e997-e4d7d8f04e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "692\n"
          ]
        }
      ],
      "source": [
        "# 유튜브 댓글 중에 ??, ㅋㅋㅋ, 응원합니다 등의 stopwords 제거\n",
        "for wd in youtube_df['content'].value_counts()[:17].index.tolist():\n",
        "  kor_stopwords.append(wd)\n",
        "print(len(kor_stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAweIT86JiIv",
        "outputId": "20d34e0e-1fb1-4887-a54c-7451766a6aef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "mbc_3rd['cleaned'] = mbc_3rd['content'].apply(lambda x: remove_stopwords(onlyhangul(x)))\n",
        "sbs_3rd['cleaned'] = sbs_3rd['content'].apply(lambda x: remove_stopwords(onlyhangul(x)))\n",
        "kbs_4th['cleaned'] = kbs_4th['content'].apply(lambda x: remove_stopwords(onlyhangul(x)))\n",
        "mbc_4th['cleaned'] = mbc_4th['content'].apply(lambda x: remove_stopwords(onlyhangul(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue5MYjq7KAsg",
        "outputId": "c0ca99ec-e7c8-4d5f-db9d-7c06f8bb266f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(79340, 7)\n",
            "(38268, 7)\n",
            "(39502, 7)\n",
            "(82489, 7)\n"
          ]
        }
      ],
      "source": [
        "mbc_3rd = mbc_3rd.loc[mbc_3rd['cleaned'] != 0]\n",
        "sbs_3rd = sbs_3rd.loc[sbs_3rd['cleaned'] != 0]\n",
        "kbs_4th = kbs_4th.loc[kbs_4th['cleaned'] != 0]\n",
        "mbc_4th = mbc_4th.loc[mbc_4th['cleaned'] != 0]\n",
        "\n",
        "print(mbc_3rd.shape)\n",
        "print(sbs_3rd.shape)\n",
        "print(kbs_4th.shape)\n",
        "print(mbc_4th.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qFSXu2ly1lS"
      },
      "source": [
        "## target_candi가 Null인 댓글 삭제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WopReLJ7y5TK"
      },
      "outputs": [],
      "source": [
        "mbc_3rd = mbc_3rd.loc[~mbc_3rd['target_candi'].isnull()]\n",
        "sbs_3rd = sbs_3rd.loc[~sbs_3rd['target_candi'].isnull()]\n",
        "kbs_4th = kbs_4th.loc[~kbs_4th['target_candi'].isnull()]\n",
        "mbc_4th = mbc_4th.loc[~mbc_4th['target_candi'].isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIle3ALT2MPX"
      },
      "source": [
        "## 이재명 대통령, 윤석열 대통령만 있는 댓글 삭제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RC_joOK62Q_1"
      },
      "outputs": [],
      "source": [
        "mbc_3rd = mbc_3rd.loc[mbc_3rd['cleaned'] != '대통령']\n",
        "sbs_3rd = sbs_3rd.loc[sbs_3rd['cleaned'] != '대통령']\n",
        "kbs_4th = kbs_4th.loc[kbs_4th['cleaned'] != '대통령']\n",
        "mbc_4th = mbc_4th.loc[mbc_4th['cleaned'] != '대통령']\n",
        "\n",
        "mbc_3rd.reset_index(drop=True, inplace=True)\n",
        "sbs_3rd.reset_index(drop=True, inplace=True)\n",
        "kbs_4th.reset_index(drop=True, inplace=True)\n",
        "mbc_4th.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92StMi8PHyAg"
      },
      "outputs": [],
      "source": [
        "# 뉴스 댓글\n",
        "# sql_state = 'SELECT comment FROM news_comment A JOIN news_list B ON B.title=A.title'\n",
        "\n",
        "# news_df = pd.read_sql_query(sql_state, conn)\n",
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4TWuH4rl3e_",
        "outputId": "d441cc44-3d92-4428-8000-023dd82465bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 47.3 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 344 kB 7.5 MB/s \n",
            "\u001b[?25h  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q mxnet\n",
        "!pip install -q gluonnlp pandas tqdm\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q transformers>=4.8.1\n",
        "!pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRX9pGOmmAXP",
        "outputId": "a97a51f6-e241-40c2-c561-bee26fe42691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.5 MB 9.4 MB/s \n",
            "\u001b[?25h  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fV9H0NGElOi6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import gluonnlp as nlp\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "e4MVgKJClo-x"
      },
      "outputs": [],
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aw2n0EOTltbQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJd-8ImnlvPf",
        "outputId": "4bb26282-503d-47c6-cd61-4ff214830fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            "/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "# GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(device)\n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJmTXVs1Q3SQ"
      },
      "source": [
        "# KoBERT 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02V0qFepmJ-t",
        "outputId": "2600c445-4787-48a5-aeb7-f6943581f884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vq2iFaaKLLZP"
      },
      "outputs": [],
      "source": [
        "# 학습 때와 달리 label 파라미터가 필요없으므로 삭제\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, dataset, sent_idx, bert_tokenizer, max_len,\n",
        "                pad, pair):\n",
        "    transform = nlp.data.BERTSentenceTransform(\n",
        "        bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "\n",
        "    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.sentences[i]\n",
        "\n",
        "  def __len__(self): # valid_length를 위해 필요한 내장 함수\n",
        "    return len(self.sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "k0fq6ofRTN6q"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self,\n",
        "                bert,\n",
        "                hidden_size=768,\n",
        "                num_classes=3, # softmax 사용 <- binary일 경우는 2\n",
        "                dr_rate=None,\n",
        "                params=None):\n",
        "    \n",
        "    super(BERTClassifier, self).__init__()\n",
        "    self.bert = bert\n",
        "    self.dr_rate = dr_rate\n",
        "              \n",
        "    self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def gen_attention_mask(self, token_ids, valid_length):\n",
        "    attention_mask = torch.zeros_like(token_ids)\n",
        "    for i, v in enumerate(valid_length):\n",
        "      attention_mask[i][:v] = 1\n",
        "    return attention_mask.float()\n",
        "\n",
        "  def forward(self, token_ids, valid_length, segment_ids):\n",
        "    attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "    \n",
        "    _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "    if self.dr_rate:\n",
        "      out = self.dropout(pooler)\n",
        "    return self.classifier(out)\n",
        "\n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device) # 모델 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6vfQIiZzBx"
      },
      "source": [
        "* model.pt 자체를 불러오면 에러 발생 -> 이는 새로운 데이터에 따라 모델이 조금이라도 달라지만 문제가 발생한다고 함\n",
        "* https://discuss.huggingface.co/t/bertencoder-object-has-no-attribute-gradient-checkpointing/11207"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05HHODUSQFvG",
        "outputId": "4591ed48-f681-4a26-bc09-6a83d1dcd1d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BERTClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 저장된 모델 불러오기\n",
        "model.load_state_dict(torch.load(PATH + 'model_state.pt')) \n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IfUAiLX7ThOR"
      },
      "outputs": [],
      "source": [
        "# setting parameters\n",
        "max_len = 128\n",
        "\n",
        "mapping = {0: '중립', 1: '긍정', 2: '부정'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCz1hUnZ1w5-"
      },
      "source": [
        "### mbc 3차"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEYDul0mLLUQ",
        "outputId": "d8dfe57f-60f4-436c-ea39-5e28f1113486"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43081/43081 [08:25<00:00, 85.25it/s]\n"
          ]
        }
      ],
      "source": [
        "unseen_test = mbc_3rd[['cleaned']]\n",
        "unseen_values = unseen_test.values\n",
        "test_set = BERTDataset(unseen_values, 0, tok, max_len, True, False)\n",
        "\n",
        "test_input = DataLoader(test_set, batch_size=1, num_workers=2) # colab은 max num works가 2\n",
        "\n",
        "result_list1 = []\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "  max_vals, max_indices = torch.max(out, 1)\n",
        "  result_list1.append(max_indices) # 중립: 0, 긍정: 1, 부정: 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZaSPgLk1x0k"
      },
      "source": [
        "### sbs 3차"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkV4ygegPv4s",
        "outputId": "31718d2a-7318-488b-d7ca-863040c285bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20042/20042 [03:51<00:00, 86.74it/s]\n"
          ]
        }
      ],
      "source": [
        "unseen_test = sbs_3rd[['cleaned']]\n",
        "unseen_values = unseen_test.values\n",
        "test_set = BERTDataset(unseen_values, 0, tok, max_len, True, False)\n",
        "\n",
        "test_input = DataLoader(test_set, batch_size=1, num_workers=2)\n",
        "\n",
        "result_list2 = []\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "  max_vals, max_indices = torch.max(out, 1)\n",
        "  result_list2.append(max_indices) # 중립: 0, 긍정: 1, 부정: 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewu1KTre11jO"
      },
      "source": [
        "### kbs 4차"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkp5XInE13aI",
        "outputId": "0c5d7e72-4ce7-471c-86df-d44012a3c712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19956/19956 [04:38<00:00, 71.60it/s]\n"
          ]
        }
      ],
      "source": [
        "unseen_test = kbs_4th[['cleaned']]\n",
        "unseen_values = unseen_test.values\n",
        "test_set = BERTDataset(unseen_values, 0, tok, max_len, True, False)\n",
        "\n",
        "test_input = DataLoader(test_set, batch_size=1, num_workers=2)\n",
        "\n",
        "result_list3 = []\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "  max_vals, max_indices = torch.max(out, 1)\n",
        "  result_list3.append(max_indices) # 중립: 0, 긍정: 1, 부정: 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZmHl2vD8GtJ"
      },
      "source": [
        "### mbc 4차"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CC1sj0N3ek7",
        "outputId": "c4b9572b-72c6-407a-8fcc-070c6ae727fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 43864/43864 [08:20<00:00, 87.64it/s]\n"
          ]
        }
      ],
      "source": [
        "unseen_test = mbc_4th[['cleaned']]\n",
        "unseen_values = unseen_test.values\n",
        "test_set = BERTDataset(unseen_values, 0, tok, max_len, True, False)\n",
        "\n",
        "test_input = DataLoader(test_set, batch_size=1, num_workers=2)\n",
        "\n",
        "result_list4 = []\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids) in enumerate(tqdm(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "  max_vals, max_indices = torch.max(out, 1)\n",
        "  result_list4.append(max_indices) # 중립: 0, 긍정: 1, 부정: 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "FBMp-1FhlhQV"
      },
      "outputs": [],
      "source": [
        "# mapping 변환\n",
        "new_list1 = []\n",
        "new_list2 = []\n",
        "new_list3 = []\n",
        "new_list4 = []\n",
        "for ele in result_list1:\n",
        "  new_list1.append(mapping[int(ele)])\n",
        "for ele in result_list2:\n",
        "  new_list2.append(mapping[int(ele)])\n",
        "for ele in result_list3:\n",
        "  new_list3.append(mapping[int(ele)])\n",
        "for ele in result_list4:\n",
        "  new_list4.append(mapping[int(ele)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "jPK12sT1TdHh"
      },
      "outputs": [],
      "source": [
        "youtube_result1 = pd.concat([mbc_3rd, pd.DataFrame(new_list1, columns=['emotion'])], axis=1)\n",
        "youtube_result2 = pd.concat([sbs_3rd, pd.DataFrame(new_list2, columns=['emotion'])], axis=1)\n",
        "youtube_result3 = pd.concat([kbs_4th, pd.DataFrame(new_list3, columns=['emotion'])], axis=1)\n",
        "youtube_result4 = pd.concat([mbc_4th, pd.DataFrame(new_list4, columns=['emotion'])], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "pckG9bn0Y8MC"
      },
      "outputs": [],
      "source": [
        "youtube_result1.to_csv(PATH + 'dataset/mbc_3rd_sentiment.csv', index=False, encoding='utf-8-sig')\n",
        "youtube_result2.to_csv(PATH + 'dataset/sbs_3rd_sentiment.csv', index=False, encoding='utf-8-sig')\n",
        "youtube_result3.to_csv(PATH + 'dataset/kbs_4th_sentiment.csv', index=False, encoding='utf-8-sig')\n",
        "youtube_result4.to_csv(PATH + 'dataset/mbc_4th_sentiment.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZmcnO-RKOM0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "KoBert_inference_live.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
