{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuxHL7WmnMWD"
      },
      "source": [
        "* https://github.com/SKTBrain/KoBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9cefEdLnTFO"
      },
      "outputs": [],
      "source": [
        "# requirements.txt\n",
        "\"\"\"\n",
        "boto3\n",
        "gluonnlp >= 0.6.0\n",
        "mxnet >= 1.4.0\n",
        "onnxruntime == 0.3.0\n",
        "sentencepiece >= 0.1.6\n",
        "torch >= 1.7.0\n",
        "transformers >= 4.8.1\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:09:37.595786Z",
          "start_time": "2022-01-10T02:09:37.592621Z"
        },
        "id": "26llQzSblmM6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import gluonnlp as nlp\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:09:38.626474Z",
          "start_time": "2022-01-10T02:09:38.624550Z"
        },
        "id": "IomEtmMDlmND"
      },
      "outputs": [],
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:09:41.378368Z",
          "start_time": "2022-01-10T02:09:41.371682Z"
        },
        "id": "LfdCHcjxlmNE"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:09:44.092831Z",
          "start_time": "2022-01-10T02:09:43.765275Z"
        },
        "id": "wWQlCuHWlmNG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:10:07.209491Z",
          "start_time": "2022-01-10T02:09:56.763434Z"
        },
        "id": "M9jDwMZvlmNH",
        "outputId": "3c1e992b-890d-49ac-abd0-df5514644fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "/db/1622817/jun_space/ML study/KoBERT/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            "/db/1622817/jun_space/ML study/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "# GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(device)\n",
        "\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:13:07.846225Z",
          "start_time": "2022-01-10T02:13:07.841103Z"
        },
        "id": "wYnWoxEulmNJ",
        "outputId": "a1372507-6654-47fe-b09d-442e4f0c305c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/db/1622817/jun_space/ML study/KoBERT'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:13:39.290708Z",
          "start_time": "2022-01-10T02:13:39.288052Z"
        },
        "id": "nafAadsplmNK"
      },
      "outputs": [],
      "source": [
        "PATH = 'jun_space/ML study/dataset/Kobert/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:14:15.861037Z",
          "start_time": "2022-01-10T02:14:15.471961Z"
        },
        "id": "imZS0P9ElmNL",
        "outputId": "58b3d441-09be-4088-ebf0-3554eba0ecfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(140625, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13503</th>\n",
              "      <td>무언가 매혹적이면서도 딱 무엇이라 정의할 단어가 떠오르지 않는다. 재미가 있다 라고...</td>\n",
              "      <td>1</td>\n",
              "      <td>무언가 매혹적이면서도 무엇이라 정의할 단어가 떠오르지 않는다 재미가 라고 말 하기엔...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135329</th>\n",
              "      <td>운 좋은 거 맞을까.</td>\n",
              "      <td>0</td>\n",
              "      <td>운 좋은 거 맞을까</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92505</th>\n",
              "      <td>이래서 외교에 영원한 우방이란 없다고 하는거지.</td>\n",
              "      <td>0</td>\n",
              "      <td>이래서 외교에 영원한 우방이란 없다고 하는거지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29809</th>\n",
              "      <td>처음부터 잊혀지지 않는 ost . 머리를 통한 이해는 영화를 보는 데 방해만 될 듯</td>\n",
              "      <td>1</td>\n",
              "      <td>처음부터 잊혀지지 않는 머리를 통한 이해는 영화를 보는 데 방해만 될 듯</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126993</th>\n",
              "      <td>배부른데.</td>\n",
              "      <td>0</td>\n",
              "      <td>배부른데</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Sentence  Emotion  \\\n",
              "13503   무언가 매혹적이면서도 딱 무엇이라 정의할 단어가 떠오르지 않는다. 재미가 있다 라고...        1   \n",
              "135329                                        운 좋은 거 맞을까.        0   \n",
              "92505                          이래서 외교에 영원한 우방이란 없다고 하는거지.        0   \n",
              "29809      처음부터 잊혀지지 않는 ost . 머리를 통한 이해는 영화를 보는 데 방해만 될 듯        1   \n",
              "126993                                             배부른데.         0   \n",
              "\n",
              "                                                  Cleaned  \n",
              "13503   무언가 매혹적이면서도 무엇이라 정의할 단어가 떠오르지 않는다 재미가 라고 말 하기엔...  \n",
              "135329                                         운 좋은 거 맞을까  \n",
              "92505                           이래서 외교에 영원한 우방이란 없다고 하는거지  \n",
              "29809            처음부터 잊혀지지 않는 머리를 통한 이해는 영화를 보는 데 방해만 될 듯  \n",
              "126993                                               배부른데  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(PATH + '전처리.csv')\n",
        "print(df.shape)\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:14:46.510907Z",
          "start_time": "2022-01-10T02:14:46.484706Z"
        },
        "id": "GSY6DxFXlmNN",
        "outputId": "040c7767-cf1b-4b51-c9ea-844583d61cce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 텍스트 중에 string이 아닌 것이 있음\n",
        "df['Cleaned'] = df['Cleaned'].astype(str)\n",
        "type(df['Cleaned'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:14:56.270721Z",
          "start_time": "2022-01-10T02:14:55.972028Z"
        },
        "id": "iaBBfqyflmNO",
        "outputId": "11152235-223f-46b1-f456-701cda06cd0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 최대 길이: 299\n",
            "문장 평균 길이: 0.005006222222222222\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('문장 최대 길이: {}'.format(max(len(str(sample)) for sample in df['Cleaned'])))\n",
        "print('문장 평균 길이: {}'.format(sum(map(len, str(df['Cleaned']))) / len(df['Cleaned'])))\n",
        "\n",
        "plt.hist([len(str(sample)) for sample in df['Cleaned']], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:15:24.642810Z",
          "start_time": "2022-01-10T02:15:24.629306Z"
        },
        "id": "qKGEnsg_lmNP",
        "outputId": "e8120745-503c-4b6d-d094-eda01cc81980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['유재석 오라버니 해피투게더 봤어요', 1], dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 밑에서 BERTDataset을 사용하기 위해 어레이로 변환\n",
        "new_df = df[['Cleaned', 'Emotion']].values # np.array()\n",
        "new_df[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:15:30.644353Z",
          "start_time": "2022-01-10T02:15:30.549090Z"
        },
        "id": "QVEDtpdplmNQ",
        "outputId": "9d337ac4-14b3-486b-a71d-55f25617cf83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape is: 119531\n",
            "test shape is: 21094\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(new_df, test_size=0.15, random_state=42, stratify=df['Emotion'])\n",
        "print(\"train shape is:\", len(train))\n",
        "print(\"test shape is:\", len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:15:38.014962Z",
          "start_time": "2022-01-10T02:15:38.010722Z"
        },
        "id": "7slMvQbGlmNR",
        "outputId": "184b2878-9a61-4e64-e708-6b36bdc6a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /db/1622817/jun_space/ML study/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:15:43.090797Z",
          "start_time": "2022-01-10T02:15:43.085843Z"
        },
        "id": "lhGJRt90lmNS"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                pad, pair):\n",
        "    transform = nlp.data.BERTSentenceTransform(\n",
        "        bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "\n",
        "    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "    self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:15:48.530948Z",
          "start_time": "2022-01-10T02:15:48.528391Z"
        },
        "id": "ELWa86E_lmNT"
      },
      "outputs": [],
      "source": [
        "# Setting parameters\n",
        "max_len = 128 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:16:06.147377Z",
          "start_time": "2022-01-10T02:15:53.706676Z"
        },
        "id": "HmA_4nbnlmNT"
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(test, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:16:19.073253Z",
          "start_time": "2022-01-10T02:16:09.332275Z"
        },
        "id": "iWFCV9jMlmNU"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self,\n",
        "                bert,\n",
        "                hidden_size = 768,\n",
        "                num_classes = 3, # softmax 사용 <- binary일 경우는 2\n",
        "                dr_rate=None,\n",
        "                params=None):\n",
        "    \n",
        "    super(BERTClassifier, self).__init__()\n",
        "    self.bert = bert\n",
        "    self.dr_rate = dr_rate\n",
        "              \n",
        "    self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "    if dr_rate:\n",
        "      self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def gen_attention_mask(self, token_ids, valid_length):\n",
        "    attention_mask = torch.zeros_like(token_ids)\n",
        "    for i, v in enumerate(valid_length):\n",
        "      attention_mask[i][:v] = 1\n",
        "    return attention_mask.float()\n",
        "\n",
        "  def forward(self, token_ids, valid_length, segment_ids):\n",
        "    attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "    \n",
        "    _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "    if self.dr_rate:\n",
        "      out = self.dropout(pooler)\n",
        "    return self.classifier(out)\n",
        "      \n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:18:08.909144Z",
          "start_time": "2022-01-10T02:18:08.903119Z"
        },
        "id": "SeDEaH_FlmNU"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01}, # 'bias', 'LayerNorm.weight' 둘 중 하나라도 포함되지 않으면 weight_deacy=0.01\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0} # 'bias', 'LayerNorm.weight' 둘 다 model.named_parameters()에 포함되면 weight_decay=0\n",
        "]\n",
        "\n",
        "# 위의 한 줄 풀어쓰기\n",
        "# for n, p in model.named_parameters():\n",
        "#     for nd in no_deacy:\n",
        "#         if not any(nd in n):\n",
        "#             [p]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:18:16.601586Z",
          "start_time": "2022-01-10T02:18:16.595273Z"
        },
        "id": "1xL9DBiJlmNV"
      },
      "outputs": [],
      "source": [
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:18:20.941327Z",
          "start_time": "2022-01-10T02:18:20.938178Z"
        },
        "id": "B5qDGtEelmNW"
      },
      "outputs": [],
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T02:18:25.721940Z",
          "start_time": "2022-01-10T02:18:25.718599Z"
        },
        "id": "fpB0OliZlmNX"
      },
      "outputs": [],
      "source": [
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "  max_vals, max_indices = torch.max(X, 1)\n",
        "  train_acc = (max_indices == Y).sum().data.cpu().numpy() / max_indices.size()[0]\n",
        "  return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T05:13:07.443327Z",
          "start_time": "2022-01-10T04:03:59.312761Z"
        },
        "id": "ekjOrTAOlmNY",
        "outputId": "3c42a9e3-4961-4903-d577-62eb7eb4cbe7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1868 [00:01<31:12,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1 loss 0.2048843950033188 train acc 0.9375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 201/1868 [01:28<12:14,  2.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 201 loss 0.25776758790016174 train acc 0.9510261194029851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 401/1868 [02:57<10:49,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 401 loss 0.2087821215391159 train acc 0.9500467581047382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 601/1868 [04:25<09:22,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 601 loss 0.2424100935459137 train acc 0.9515650998336106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 801/1868 [05:54<07:53,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 801 loss 0.13704341650009155 train acc 0.9519155742821473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 1001/1868 [07:22<06:23,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1001 loss 0.06696699559688568 train acc 0.9519230769230769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1201/1868 [08:51<04:55,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1201 loss 0.24186047911643982 train acc 0.9527347002497918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1401/1868 [10:20<03:26,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1401 loss 0.1063297688961029 train acc 0.952935403283369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1601/1868 [11:48<01:58,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1601 loss 0.0924442857503891 train acc 0.9528126951905059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1801/1868 [13:17<00:29,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 batch id 1801 loss 0.10043050348758698 train acc 0.9522487506940589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1868/1868 [13:47<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 train acc 0.9522342715128729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1868 [00:01<31:52,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1 loss 0.2856529951095581 train acc 0.890625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 201/1868 [01:29<12:18,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 201 loss 0.22572115063667297 train acc 0.9455068407960199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 401/1868 [02:58<10:52,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 401 loss 0.19240665435791016 train acc 0.946267144638404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 601/1868 [04:27<09:22,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 601 loss 0.3196406364440918 train acc 0.9474833610648918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 801/1868 [05:55<07:53,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 801 loss 0.14429576694965363 train acc 0.9485994069912609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 1001/1868 [07:24<06:24,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1001 loss 0.0651778057217598 train acc 0.9485046203796204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1201/1868 [08:53<04:55,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1201 loss 0.2010831981897354 train acc 0.949169962531224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1401/1868 [10:21<03:27,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1401 loss 0.11821572482585907 train acc 0.9495672733761599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1601/1868 [11:50<01:58,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1601 loss 0.10959187150001526 train acc 0.949416380387258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1801/1868 [13:19<00:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 batch id 1801 loss 0.10323628783226013 train acc 0.9490474042198779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1868/1868 [13:49<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 train acc 0.9489763722548678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1868 [00:01<31:21,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1 loss 0.21579866111278534 train acc 0.921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 201/1868 [01:29<12:18,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 201 loss 0.24670669436454773 train acc 0.945429104477612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 401/1868 [02:58<10:49,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 401 loss 0.23895768821239471 train acc 0.9452540523690773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 601/1868 [04:27<09:22,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 601 loss 0.22549767792224884 train acc 0.9459234608985025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 801/1868 [05:56<07:52,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 801 loss 0.16231194138526917 train acc 0.9460635143570537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 1001/1868 [07:24<06:25,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1001 loss 0.09690988808870316 train acc 0.9461788211788211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1201/1868 [08:53<04:59,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1201 loss 0.4347839057445526 train acc 0.9464508742714405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1401/1868 [10:22<03:27,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1401 loss 0.124654620885849 train acc 0.9463998929336188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1601/1868 [11:51<01:58,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1601 loss 0.05722328647971153 train acc 0.9462640537164272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1801/1868 [13:20<00:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 batch id 1801 loss 0.21237558126449585 train acc 0.9460108967240421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1868/1868 [13:49<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 train acc 0.9458645610278372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1868 [00:01<31:57,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1 loss 0.23007431626319885 train acc 0.90625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 201/1868 [01:29<12:19,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 201 loss 0.2981634736061096 train acc 0.9419309701492538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 401/1868 [02:58<10:51,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 401 loss 0.22519446909427643 train acc 0.9427213216957606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 601/1868 [04:27<09:22,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 601 loss 0.2781173586845398 train acc 0.94238768718802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 801/1868 [05:55<07:55,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 801 loss 0.15175698697566986 train acc 0.9423377028714107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 1001/1868 [07:24<06:25,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1001 loss 0.13253159821033478 train acc 0.9422608641358642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1201/1868 [08:53<04:56,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1201 loss 0.3090742528438568 train acc 0.9428340965861782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1401/1868 [10:22<03:27,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1401 loss 0.11441253125667572 train acc 0.9428756245538901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1601/1868 [11:51<01:58,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1601 loss 0.07387039810419083 train acc 0.9430238913179263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1801/1868 [13:20<00:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 batch id 1801 loss 0.14141525328159332 train acc 0.9425839811215991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1868/1868 [13:50<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 train acc 0.9425483043673124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/1868 [00:01<31:25,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1 loss 0.09386042505502701 train acc 0.96875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 201/1868 [01:29<12:21,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 201 loss 0.25063949823379517 train acc 0.939521144278607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 401/1868 [02:58<10:50,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 401 loss 0.263238787651062 train acc 0.9394872194513716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 601/1868 [04:27<09:28,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 601 loss 0.2042059749364853 train acc 0.9405418053244592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 801/1868 [05:56<07:54,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 801 loss 0.08599235117435455 train acc 0.9407381398252185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 1001/1868 [07:26<06:33,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1001 loss 0.14871269464492798 train acc 0.9419018481518482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 1201/1868 [08:55<04:55,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1201 loss 0.20566558837890625 train acc 0.9425738967527061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 1401/1868 [10:24<03:26,  2.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1401 loss 0.049175966531038284 train acc 0.9428533190578159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1601/1868 [11:53<01:58,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1601 loss 0.0992196798324585 train acc 0.9431410056214866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 1801/1868 [13:21<00:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 batch id 1801 loss 0.1047637090086937 train acc 0.9434862576346474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1868/1868 [13:51<00:00,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 train acc 0.9435351280439221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "  train_acc = 0.0\n",
        "  test_acc = 0.0\n",
        "  model.train()\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "    valid_length= valid_length\n",
        "    label = label.long().to(device)\n",
        "\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "    loss = loss_fn(out, label)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step() # Update learning rate schedule\n",
        "    train_acc += calc_accuracy(out, label)\n",
        "\n",
        "    if batch_id % log_interval == 0:\n",
        "      print(\"epoch {} batch id {} loss {} train acc {}\".format(e + 1, batch_id + 1, loss.data.cpu().numpy(), train_acc / (batch_id + 1)))\n",
        "    \n",
        "    # 추후 학습 재개를 위해 필요한 정보 저장\n",
        "#     torch.save({\n",
        "#       'epoch': epoch,\n",
        "#       'optimizer_state_dict': optimizer.state_dict(),\n",
        "#       'model_state_dict': model.state_dict(),\n",
        "#       'scheduler': scheduler.state_dict(),\n",
        "#       'loss': loss\n",
        "#     }, base_dir + f'_{epoch:04d}.pth')\n",
        "\n",
        "  print(\"epoch {} train acc {}\".format(e + 1, train_acc / (batch_id + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T05:13:39.684147Z",
          "start_time": "2022-01-10T05:13:39.249695Z"
        },
        "id": "W2A-2hb_lmNZ"
      },
      "outputs": [],
      "source": [
        "# 학습 가능한 매개변수가 담겨있는 딕셔너리(Dictionary), 가중치와 편향이 이에 해당\n",
        "torch.save(model.state_dict(), PATH + 'model_state.pt') # 또 다른 확장자명: .pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-01-10T05:13:27.609645Z",
          "start_time": "2022-01-10T05:13:27.090799Z"
        },
        "id": "1T7u2t2flmNa"
      },
      "outputs": [],
      "source": [
        "# 모델 전체 저장: 모델 파라미터 뿐만 아니라, 옵티마이저(Optimizer), 에포크, 스코어 등 모든 상태를 저장\n",
        "torch.save(model, PATH + 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MoAYOldlmNa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "KoBERT_training.ipynb",
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
